## Deploy Ollama on Kubernetes
[ollama_on_kubernetes](https://github.com/vineethac/Ollama/tree/main/ollama_on_kubernetes)

## Prompt Ollama/ LLM models using LangChain and Python
[ollama_langchain](https://github.com/vineethac/Ollama/tree/main/ollama_langchain)


